---
title: API MediaStream
slug: WebRTC/MediaStream_API
tags:
  - API
  - Audio
  - Media
  - Overview
translation_of: Web/API/Media_Streams_API
---
<div>{{DefaultAPISidebar("Media Capture and Streams")}}</div>

<p>L'<strong>API Processing MediaStream</strong>, souvent appelée <em>Media Stream API</em> ou <em>Stream API</em>, est la partie de <a href="/fr/docs/WebRTC">WebRTC</a> décrivant un flux de données audio ou vidéo, les méthodes pour les manipuler, les contraintes associées au type de données, les erreurs et succès des callbacks avec les données asynchrones, et les évènements déclenchés durant le processus.</p>

<h2 id="Concepts_de_base">Concepts de base</h2>

<p>L'API est basée sur la manipulation de l'objet {{domxref("MediaStream")}} représentant un flux de données audio ou vidéo. Typiquement, un {{domxref("MediaStream")}} est une simple chaine URL qui peut être utilisée pour référencer une donnée stockée dans un {{domxref("File")}} DOM, ou un objet {{domxref("Blob")}} crée avec {{domxref("window.URL.createObjectURL()")}}, tel que décrit dans <a href="/en-US/docs/WebRTC/taking_webcam_photos#Get_the_video">cette vidéo</a>.</p>

<p>Un {{domxref("MediaStream")}} consiste en zéro ou plus objets {{domxref("MediaStreamTrack")}}, représentant différentes <strong>pistes</strong> audio ou vidéos. Chaque {{domxref("MediaStreamTrack")}} peut avoir un ou plusieurs <strong>canal</strong>. Le canal représente la plus petite unité d'un flux média, tel un signal audio d'un haut-parleur, séparé en <em>gauche</em> et <em>droite</em> sur une piste audio en stéréo.</p>

<p><code><font face="Lucida Grande, Lucida Sans Unicode, DejaVu Sans, Lucida, Arial, Helvetica, sans-serif">Les objets </font></code> {{domxref("MediaStream")}} ont une seule <strong>entrée </strong>et une seule <strong>sortie</strong>. Un objet {{domxref("MediaStream")}} généré par <a href="/en-US/docs/WebRTC/navigator.getUserMedia">getUserMedia()</a> est dit <em>local</em>, et sa source d'entrée provient de l'une des caméra ou microphone de l'utilisateur. Un objet {{domxref("MediaStream")}} non local peut représenter un média tel que {{HTMLElement("video")}} ou {{HTMLElement("audio")}}, un flux provenant du réseau et obtenu via l'API WebRTC <a href="/en-US/docs/WebRTC/PeerConnection_API">PeerConnection</a>, ou un flux créé en utilisant l'API <a href="/en-US/docs/Web_Audio_API">Web Audio</a> {{domxref("MediaStreamAudioSourceNode")}}. La sortie d'un objet {{domxref("MediaStream")}} est liée à un <strong>consommateur</strong>. Elle peut-être un élément média tel que {{HTMLElement("audio")}} ou {{HTMLElement("video")}}, l'API WebRTC <a href="/en-US/docs/WebRTC/PeerConnection_API">PeerConnection</a> ou l'<a href="/en-US/docs/Web_Audio_API">API Web Audio</a> {{domxref("MediaStreamAudioDestinationNode")}}.</p>

<h2 id="Interfaces">Interfaces</h2>

<p>Dans ces articles de référence, on trouvera les informations fondamentales sur les différentes interfaces qui composent l'API <em>Media Capture and Streams API</em>.</p>

<div class="index">
<ul>
 <li>{{domxref("BlobEvent")}}</li>
 <li>{{domxref("CanvasCaptureMediaStreamTrack")}}</li>
 <li>{{domxref("InputDeviceInfo")}}</li>
 <li>{{domxref("MediaDeviceKind")}}</li>
 <li>{{domxref("MediaDeviceInfo")}}</li>
 <li>{{domxref("MediaDevices")}}</li>
 <li>{{domxref("MediaStream")}}</li>
 <li>{{domxref("MediaStreamConstraints")}}</li>
 <li>{{domxref("MediaStreamEvent")}}</li>
 <li>{{domxref("MediaStreamTrack")}}</li>
 <li>{{domxref("MediaStreamTrackEvent")}}</li>
 <li>{{domxref("MediaTrackCapabilities")}}</li>
 <li>{{domxref("MediaTrackConstraints")}}</li>
 <li>{{domxref("MediaTrackSettings")}}</li>
 <li>{{domxref("MediaTrackSupportedConstraints")}}</li>
 <li>{{domxref("NavigatorUserMedia")}}</li>
 <li>{{domxref("NavigatorUserMediaError")}}</li>
 <li>{{domxref("OverconstrainedError")}}</li>
 <li>{{domxref("URL")}}</li>
</ul>
</div>

<p>Les premières versions de la spécification pour Media Capture and Streams API incluaient des interfaces séparées <code>AudioStreamTrack</code> et <code>VideoStreamTrack</code>, chacunes basées sur {{domxref("MediaStreamTrack")}} et qui représentaient des types de flux différents. Celles-ci n'existent plus et il faut utiliser <code>MediaStreamTrack</code> directement à la place.</p>

<h2 id="Évènements">Évènements</h2>

<div class="index">
<ul>
 <li>{{event("addtrack")}}</li>
 <li>{{event("ended")}}</li>
 <li>{{event("muted")}}</li>
 <li>{{event("overconstrained")}}</li>
 <li>{{event("removetrack")}}</li>
 <li>{{event("started")}}</li>
 <li>{{event("unmuted")}}</li>
</ul>
</div>

<h2 id="Guides_et_tutorials">Guides et tutorials</h2>

<p>Les articles qui suivent fournissent des manuels et guides pour utiliser cette API et réaliser des certaines tâches avec elle.</p>

<p>{{LandingPageListSubpages}}</p>

<h2 id="Compatibilité_des_navigateurs">Compatibilité des navigateurs</h2>



<p>{{Compat("api.MediaStream")}}</p>

<h2 id="Voir_aussi">Voir aussi</h2>

<ul>
 <li><a href="/fr/docs/Web/API/WebRTC_API" title="/en-US/docs/WebRTC">WebRTC</a> - la page d'introduction à l'API</li>
 <li>{{domxref("mediaDevices.getUserMedia()")}}</li>
 <li><a href="/fr/docs/Web/API/WebRTC_API/Taking_still_photos">Prendre des clichés avec WebRTC</a> : un tutoriel/une démonstration sur l'utilisation de <code>getUserMedia()</code>.</li>
</ul>
